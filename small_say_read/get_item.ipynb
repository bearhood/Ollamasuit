{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import re\n",
    "\n",
    "\n",
    "driver = webdriver.Firefox()\n",
    "driver.get('https://www.wenku8.net/modules/article/reader.php?aid=2509')\n",
    "page_html = driver.page_source\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(page_html, 'html.parser')\n",
    "tables = soup.find_all('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bowli\\AppData\\Local\\Temp\\ipykernel_27248\\2929733660.py:6: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'第一卷 过去的恋情不肯结束'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables = soup.find_all('table')\n",
    "import pandas as pd\n",
    "# 將每個表格轉換為 DataFrame 並存儲在列表中\n",
    "dataframes = []\n",
    "for table in tables:\n",
    "    df = pd.read_html(str(table))[0]\n",
    "    dataframes.append(df)\n",
    "\n",
    "\n",
    "dataframes[0].iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bowli\\AppData\\Local\\Temp\\ipykernel_27248\\3214481958.py:4: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'上面已完成階段性任務，基本上只有一個 table\\n\\ndatas frames 才有意義\\n\\n如果整列的 title/ element 相同- 代表為卷名， 需要另外存一個資料夾\\n\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes = []\n",
    "link_dataframes = []\n",
    "for table in tables:\n",
    "    df = pd.read_html(str(table))[0]\n",
    "    dataframes.append(df)\n",
    "    # 以下開始創造另外一個 table 與前面一個 list 相同格式\n",
    "    links = []\n",
    "    for row in table.find_all('tr'):\n",
    "        link_row = []\n",
    "        for cell in row.find_all(['td', 'th']):\n",
    "            link = cell.find('a')\n",
    "            if link and link.has_attr('href'):\n",
    "                link_row.append(link['href'])\n",
    "            else:\n",
    "                link_row.append(None)\n",
    "        links.append(link_row)\n",
    "            \n",
    "        # 創建包含鏈接的 DataFrame\n",
    "    link_df = pd.DataFrame(links)\n",
    "    link_dataframes.append(link_df)\n",
    "title = soup.find('div', attrs={'id':'title'})\n",
    "'''上面已完成階段性任務，基本上只有一個 table\n",
    "\n",
    "datas frames 才有意義\n",
    "\n",
    "如果整列的 title/ element 相同- 代表為卷名， 需要另外存一個資料夾\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "mother_path = os.path.join( './data' , title.text )\n",
    "os.makedirs( mother_path , exist_ok=True)\n",
    "\n",
    "data_list = dataframes[0].values.tolist()\n",
    "href_list = link_dataframes[0].values.tolist()\n",
    "chapter_count = 0 \n",
    "for idx_row,  row_list in enumerate( data_list ):\n",
    "    if(row_list[0]==row_list[1] ):\n",
    "        state_path = os.path.join( mother_path , f'{chapter_count}_' + row_list[0] )\n",
    "        os.makedirs( state_path , exist_ok=True)\n",
    "        #確定是第幾卷的內容\n",
    "        count = 0\n",
    "        chapter_count +=1\n",
    "    else: #要進入網站讀取資料\n",
    "        for idx_col, col_text in enumerate(row_list):\n",
    "            try:\n",
    "                driver.get(href_list[idx_row][idx_col])\n",
    "                page_html = driver.page_source\n",
    "                soup = BeautifulSoup(page_html, 'html.parser')\n",
    "                content_text = soup.find('div', attrs={'id':'content'})\n",
    "                temp_text = content_text.text\n",
    "                pattern = r'\\\\(?!n)'\n",
    "                replaced_text = re.sub(pattern, ' ', temp_text)\n",
    "                file_path = os.path.join( state_path , f'{count}_'+col_text + '.txt')\n",
    "                with open(file_path,'w', encoding='UTF-8') as file:\n",
    "                    file.write(replaced_text)\n",
    "                time.sleep( random.randint( 2 , 10))\n",
    "                count += 1\n",
    "            except:\n",
    "                pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
